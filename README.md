# React Native Dictation Module

Low-latency, native-backed dictation for React Native with real-time waveform streaming. Supports both iOS and Android platforms.

## Status Snapshot
- **Primary Platform**: React Native (iOS + Android)
- **iOS**: Native implementation using `AVAudioEngine` + `SFSpeechRecognizer` with <100 ms latency target
- **Android**: Native implementation using `AudioRecord` + `SpeechRecognizer` (Kotlin)
- Implementation documentation and troubleshooting guides live in `docs/react_native_migration/`

## Feature Highlights
- ğŸ¤ **Streaming speech recognition** with partial + final transcripts
- ğŸ“Š **Real-time waveform visualization** at 30 FPS
- ğŸ’¾ **Audio preservation** in canonical `.m4a` format (AAC-LC, mono, 44.1kHz, 64kbps)
- ğŸ”„ **Audio normalization** for imported files
- â±ï¸ **Duration guardrails** (60-minute limit)
- âš¡ **Pre-warmed audio engine** for instant mic activation
- ğŸ” **Robust permission handling** for microphone and speech recognition
- ğŸ“± **Cross-platform** support for iOS and Android

## Quick Start

### Installation

```bash
npm install react-native-dictation
# or
yarn add react-native-dictation
```

### Basic Usage

```typescript
import { useDictation, Waveform } from 'react-native-dictation';

function MyComponent() {
  const { isListening, startListening, stopListening } = useDictation({
    onResult: (result) => {
      console.log('Transcript:', result.text);
    },
  });

  return (
    <View>
      <Waveform isListening={isListening} />
      <Button 
        title={isListening ? "Stop" : "Start"} 
        onPress={isListening ? stopListening : startListening} 
      />
    </View>
  );
}
```


## System Architecture

```
React Native App
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TypeScript Layer                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ DictationService     â”‚   â”‚ WaveformController (useState)  â”‚  â”‚
â”‚  â”‚ - initialize()       â”‚   â”‚ - levels[]                     â”‚  â”‚
â”‚  â”‚ - startListening()   â”‚   â”‚ - updateLevel()                â”‚  â”‚
â”‚  â”‚ - stopListening()    â”‚   â”‚ - reset()                      â”‚  â”‚
â”‚  â”‚ - cancelListening()  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚ - normalizeAudio()   â”‚                                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚             â”‚ NativeModules                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Native Bridge (iOS Swift / Android Kotlin)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ DictationModule     â”‚   â”‚ Event Emitters                   â”‚ â”‚
â”‚  â”‚ (RCTEventEmitter)   â”‚   â”‚ - onResult                       â”‚ â”‚
â”‚  â”‚                     â”‚   â”‚ - onStatus                       â”‚ â”‚
â”‚  â”‚ Method exports:     â”‚   â”‚ - onAudioLevel                   â”‚ â”‚
â”‚  â”‚ - initialize        â”‚   â”‚ - onAudioFile                    â”‚ â”‚
â”‚  â”‚ - startListening    â”‚   â”‚ - onError                        â”‚ â”‚
â”‚  â”‚ - stopListening     â”‚   â”‚                                  â”‚ â”‚
â”‚  â”‚ - cancelListening   â”‚   â”‚                                  â”‚ â”‚
â”‚  â”‚ - getAudioLevel     â”‚   â”‚                                  â”‚ â”‚
â”‚  â”‚ - normalizeAudio    â”‚   â”‚                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                                                   â”‚
â”‚             â–¼                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Native Managers                                               â”‚â”‚
â”‚  â”‚ iOS:                                                          â”‚â”‚
â”‚  â”‚ - AudioEngineManager.swift   (AVAudioEngine)                 â”‚â”‚
â”‚  â”‚ - SpeechRecognizerManager.swift (SFSpeechRecognizer)        â”‚â”‚
â”‚  â”‚ - AudioEncoderManager.swift  (AAC encoding)                  â”‚â”‚
â”‚  â”‚                                                               â”‚â”‚
â”‚  â”‚ Android:                                                      â”‚â”‚
â”‚  â”‚ - AudioEngineManager.kt      (AudioRecord)                  â”‚â”‚
â”‚  â”‚ - DictationCoordinator.kt   (SpeechRecognizer)             â”‚â”‚
â”‚  â”‚ - AudioEncoderManager.kt     (MediaCodec AAC)               â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Runtime Flow
1. React Native app calls `DictationService.initialize()` to pre-warm the native audio engine and speech recognizer.
2. `initialize()` triggers native pre-warm and returns once both iOS/Android managers report ready.
3. `startListening()` sets up event listeners, then invokes the native module method.
4. Native module (iOS Swift / Android Kotlin) requests microphone permission, starts the audio engine, shares buffers with the speech recognizer, and begins waveform streaming.
5. Native emits `onResult`, `onStatus`, `onAudioLevel`, or `onError` events. TypeScript service surfaces them to React components and the waveform controller.
6. `stopListening()` finalizes the recognition request; `cancelListening()` drops audio immediately. Event listeners are cleaned up automatically.

## API Overview

### Native Module Methods

| Method            | Args | Returns | Description |
|-------------------|------|---------|-------------|
| `initialize`      | â€”    | `Promise<void>` | Pre-warm audio engine + speech recognizer |
| `startListening`  | `options?: DictationSessionOptions` | `Promise<void>` | Start listening with optional audio preservation |
| `stopListening`   | â€”    | `Promise<void>` | Stop and finalize recognition |
| `cancelListening` | â€”    | `Promise<void>` | Cancel without finalizing |
| `getAudioLevel`   | â€”    | `Promise<number>` | Get current audio level (0-1) |
| `normalizeAudio`  | `sourcePath: string` | `Promise<NormalizedAudioResult>` | Normalize audio file to canonical format |

### Events

| Event        | Payload | Description |
|--------------|---------|-------------|
| `onResult`   | `{ text: string, isFinal: boolean }` | Partial + final transcripts |
| `onStatus`   | `{ status: string }` | Status updates (ready, listening, stopped, etc.) |
| `onAudioLevel` | `{ level: number }` | Audio level updates at 30 FPS |
| `onAudioFile` | `{ path, durationMs, fileSizeBytes, sampleRate, channelCount, wasCancelled }` | Audio file saved (when preservation enabled) |
| `onError`    | `{ message: string, code?: string }` | Error events |


## React Native API

### `DictationService`
Main service class for managing dictation sessions.

- `initialize(): Promise<void>` - Pre-warm audio engine and speech recognizer
- `startListening(options?): Promise<void>` - Start listening with callbacks
- `stopListening(): Promise<void>` - Stop and finalize
- `cancelListening(): Promise<void>` - Cancel without finalizing
- `getAudioLevel(): Promise<number>` - Get current audio level (0-1)
- `normalizeAudio(sourcePath): Promise<NormalizedAudioResult>` - Normalize audio file

### `useDictation` Hook
React hook that wraps `DictationService` with state management.

Returns: `{ isListening, status, audioLevel, startListening, stopListening, cancelListening, initialize }`

### Components
- `Waveform` - Real-time waveform visualization component
- `AudioControlsDecorator` - Convenience wrapper with controls and waveform


## Platform Support

### iOS
- **Minimum Version**: iOS 13.0+
- **Offline Support**: Available when offline dictation packs are installed (Settings â†’ General â†’ Keyboard â†’ Dictation Languages)
- **Permissions**: Microphone + Speech Recognition

### Android
- **Minimum Version**: API 21+ (Android 5.0)
- **Speech Recognition**: Uses Android `SpeechRecognizer` (typically requires Google Play Services)
- **Permissions**: Microphone (speech recognition handled by system)

## Installation & Setup

### iOS Setup
1. Install CocoaPods dependencies: `cd ios && pod install`
2. Add permissions to `Info.plist`:
   - `NSMicrophoneUsageDescription`
   - `NSSpeechRecognitionUsageDescription`

### Android Setup
1. Register `DictationPackage` in `MainApplication.java`/`MainApplication.kt`
2. Permissions are automatically declared in the library's manifest


## Native Implementation Details

### iOS (Swift)
- **`AudioEngineManager.swift`**: Configures `AVAudioSession` (record + measurement mode, 5 ms buffer, 16 kHz sample rate), requests mic permission, installs tap for waveform + recognition, smooths RMS/peak values, streams audio levels at 30 FPS.
- **`SpeechRecognizerManager.swift`**: Manages `SFSpeechRecognizer`, tracks authorization, receives shared buffers, emits partial/final transcripts, maps Speech framework error codes.
- **`DictationCoordinator.swift`**: Core coordinator for React Native bridge calls, state machine, error mapping, event fan-out.

### Android (Kotlin)
- **`AudioEngineManager.kt`**: Uses `AudioRecord` for audio capture, calculates audio levels, manages recording thread.
- **`DictationCoordinator.kt`**: Orchestrates `SpeechRecognizer` and audio recording, handles recognition callbacks.
- **`AudioEncoderManager.kt`**: Encodes audio to AAC/M4A format using `MediaCodec`.

See migration documentation in `docs/react_native_migration/` for implementation details.

## Waveform & Audio Level Streaming
- **iOS**: Single audio tap feeds both waveform smoothing and speech recognizer (AVAudioEngine limitation).
- **Android**: AudioRecord buffers are processed for both waveform visualization and speech recognition.
- Levels are normalized to `0â€“1` using blended RMS + peak + decibel shaping for consistent visualization.
- Audio levels stream at 30 FPS via `onAudioLevel` events.

## Audio Preservation
- Enable audio preservation via `preserveAudio: true` in `startListening()` options.
- Receive saved audio files via `onAudioFile` callback with metadata (path, duration, size, sample rate, channels).
- **iOS**: Recordings stored in app's Documents directory, default format `.m4a` (AAC-LC, 44.1 kHz, mono, 64 kbps).
- **Android**: Recordings stored in app's files directory, format `.m4a` (AAC-LC, 44.1 kHz, mono, 64 kbps).
- Control file retention on cancel via `deleteAudioIfCancelled` option (default: `true`).
- Files are pre-encoded to AAC, ready for upload without additional processing.

## Permissions

### iOS
Add to `ios/YourApp/Info.plist`:
```xml
<key>NSMicrophoneUsageDescription</key>
<string>We need access to your microphone for low-latency dictation.</string>
<key>NSSpeechRecognitionUsageDescription</key>
<string>We need speech recognition to convert your voice into text.</string>
```

### Android
Permissions are automatically declared in the library's `AndroidManifest.xml`. No additional configuration needed.

## Project Structure
```
react-native-dictation/
â”œâ”€â”€ react-native/                   # React Native package
â”‚   â”œâ”€â”€ src/                        # TypeScript source
â”‚   â”‚   â”œâ”€â”€ DictationService.ts     # Main service class
â”‚   â”‚   â”œâ”€â”€ hooks/                  # React hooks (useDictation, useWaveform)
â”‚   â”‚   â”œâ”€â”€ components/             # React components (Waveform, AudioControlsDecorator)
â”‚   â”‚   â””â”€â”€ types/                  # TypeScript type definitions
â”‚   â”œâ”€â”€ ios/                        # iOS native implementation (Swift)
â”‚   â”‚   â”œâ”€â”€ DictationModule.swift   # React Native bridge
â”‚   â”‚   â”œâ”€â”€ DictationCoordinator.swift
â”‚   â”‚   â”œâ”€â”€ AudioEngineManager.swift
â”‚   â”‚   â””â”€â”€ SpeechRecognizerManager.swift
â”‚   â”œâ”€â”€ android/                    # Android native implementation (Kotlin)
â”‚   â”‚   â””â”€â”€ src/main/java/com/reactnativedictation/
â”‚   â”‚       â”œâ”€â”€ DictationModule.kt
â”‚   â”‚       â”œâ”€â”€ DictationCoordinator.kt
â”‚   â”‚       â””â”€â”€ AudioEngineManager.kt
â”œâ”€â”€ docs/react_native_migration/    # Implementation documentation
â””â”€â”€ README.md                       # This file
```

## Documentation

- **`docs/react_native_migration/`** - Implementation documentation and phases
  - `01_NATIVE_MODULE_BRIDGE.md` - iOS native module setup
  - `08_ANDROID_IMPLEMENTATION.md` - Android implementation guide
  - `09_TESTING_AND_VALIDATION.md` - Testing strategy

## License

This project is available for use in your applications.
